{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "* [Sequence to Sequence Learning with Neural Networks](https://mlexplained.com/2018/02/15/language-modeling-tutorial-in-torchtext-practical-torchtext-part-2/)\n",
    "* [Language modeling tutorial in torchtext](https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb)\n",
    "* [Language Models and Contextualised Word Embeddings](http://www.davidsbatista.net/blog/2018/12/06/Word_Embeddings/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.data import Field, BPTTIterator\n",
    "\n",
    "from model import RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a torch.device which is used to tell PyTorch to put the tensors on the GPU or not. We use the `torch.cuda.is_available()` function, which will return True if a GPU is detected on our computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchtext.data.Field` handles how the data should be processed, the arguments for which can be found [here](https://pytorch.org/text/data.html). We set the `tokenize` argument to \"basic english\". The Field also appends the \"start of sequence\" and \"end of sequence\" tokens via the `init_token` and `eos_token` arguments, and converts all words to lowercase.\n",
    "\n",
    "A tokenizer is used to turn a string containing a sentence into a list of individual tokens that make up that string, e.g. \"good morning!\" becomes [\"good\", \"morning\", \"!\"]. We'll talk about the sentences being a sequence of tokens, instead of saying they're a sequence of words. This is because \"good\" and \"morning\" are both words and tokens, but \"!\" is a token, not a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# define how data should look\n",
    "TEXT = Field(tokenize=get_tokenizer(\"basic_english\"),\n",
    "             init_token='<sos>',\n",
    "             eos_token='<eos>',\n",
    "             lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and load the train, validation, test datasets from WikiText2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training words:   2086708\n",
      "Number of validation words: 218177\n",
      "Number of testing words:    246217\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "train_x, val_x, test_x = WikiText2.splits(TEXT)\n",
    "print(f\"Number of training words:   {len(train_x.examples[0].text)}\")\n",
    "print(f\"Number of validation words: {len(val_x.examples[0].text)}\")\n",
    "print(f\"Number of testing words:    {len(test_x.examples[0].text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyperparameters for the model and training processs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_precomputed_embeds = False\n",
    "\n",
    "# hyperparameters of model\n",
    "embed_size = 200\n",
    "rnn_hidden_size = 128\n",
    "rnn_num_layers = 1\n",
    "hidden_layer_size=None\n",
    "\n",
    "# hyperparameters for training\n",
    "epochs = 2\n",
    "batch_size = 20\n",
    "seq_len = 30\n",
    "learning_rate = 1e-3\n",
    "clip = 5\n",
    "solver = \"adam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next build the vocabulary for our language modelling task. The vocabulary is used to associate each unique token with an index (an integer).\n",
    "\n",
    "It is important to note that our vocabulary should only be built from the training set and not the validation/test set. This prevents \"information leakage\" into our model, giving us artifically inflated validation/test scores.\n",
    "\n",
    "Using the `min_freq` argument, we only allow tokens that appear at least 2 times to be in our vocabulary. Tokens that appear only once are converted into an <unk> (unknown) token. Additionally, with the `vectors` argument we can use precomputed static word embeddings, in this case GloVe vectors with 200 dimensions:\n",
    "    \n",
    "* **Static word embeddings** map each token to a single vector, e.g. Skip-Gram (word2vec), GloVe, fastText. This means that the same word will have the same embedding regardless of the context it occurs in.\n",
    "    \n",
    "* **Contextual word embeddings** take into consideration the context of words, such that a word may have a different embedding depending on the words surrounding it e.g. BERT, ELMO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens in vocabulary: 28785\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary from the training data\n",
    "TEXT.build_vocab(train_x, min_freq=2, vectors=\"glove.6B.200d\" if use_precomputed_embeds else None)\n",
    "vocab_size = len(TEXT.vocab.stoi)\n",
    "print(f\"Number of unique tokens in vocabulary: {len(TEXT.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the iterator:\n",
    "* Divides the corpus into batches of sequence length => [`bppt_len`, `batch_size`].\n",
    "* Does not use padding and so drops the left over data after batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BPTTIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_iter, val_iter, test_iter = BPTTIterator.splits((train_x, val_x, test_x),\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      bptt_len=seq_len,\n",
    "                                                      device=device,\n",
    "                                                      repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the Model:\n",
    "* Here in the forward pass we keep the hidden state of the RNN because the entire dataset is a continuous corpus, meaning we want to retain the hidden state between sequences within a batch. \n",
    "\n",
    "* We can't retain the entire history as this would mean the model will try to backpropogate to the beginning of the dataset which requires a lot of memory and time. Hence we have a `repackage_hidden()` function used at the start of each batch, which treats the hidden state of the RNN from the previous batch as a constant.\n",
    "\n",
    "* We initialise all the weights of the network from a uniform distribution, $\\mathcal{U}(-0.1,0.1)$ and initialise the biases to $0$.\n",
    "\n",
    "* Additionally, we have a `init_hidden()` function which initialises the hidden state of the RNN to a zero vector. Remember if using an LSTM then we have both the hidden state and the cell state to initialise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (encoder): Embedding(28785, 200)\n",
      "  (rnn): LSTM(200, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=28785, bias=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(model=\"lstm\",\n",
    "          input_size=vocab_size,\n",
    "          embed_size=embed_size,\n",
    "          rnn_hidden_size=rnn_hidden_size, \n",
    "          rnn_num_layers=rnn_num_layers, \n",
    "          hidden_layer_size=hidden_layer_size,\n",
    "          precomputed_embeds=Text.vocab.vectors if use_precomputed_embeds else None)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the training procedure:\n",
    "* We use the `torch.nn.CrossEntropyLoss` function. This loss takes the index of the correct class as the ground truth instead of a one-hot vector. Unfortunately, it only takes tensors of dimension 2 so we need to rehape our prediction and target matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, \n",
    "          train_iter, \n",
    "          val_iter, \n",
    "          epochs, \n",
    "          batch_size, \n",
    "          seq_len, \n",
    "          learning_rate, \n",
    "          clip,\n",
    "          solver,\n",
    "          device):\n",
    "    \"\"\"\n",
    "    Fit model with the training data and validate using the validation data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : `torch.nn.Module` \n",
    "        The model.\n",
    "    train_iter : `torchtext.data.iterator.BPTTIterator`\n",
    "        The training data iterator.\n",
    "    val_iter : `torchtext.data.iterator.BPTTIterator`\n",
    "        The validation data iterator.\n",
    "    batch_size : `int`\n",
    "        The number of sequences per batch.\n",
    "    seq_len : `int`\n",
    "        The number of encoded chars in a sequence.\n",
    "    learning_rate : `float`\n",
    "        The learning rate.\n",
    "    clip : `float`\n",
    "        Value for clipping the gradients by.\n",
    "    solver : `str`\n",
    "        The optimiser to use, either \"adam\" or \"sgd\".\n",
    "    device : `torch.device`\n",
    "        Whether working on GPU or CPU.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    measures : `dict` of `list`s\n",
    "        Dictionary of training and validation \n",
    "        accuracies and losses for each epoch.\n",
    "    \"\"\"  \n",
    "    # send model to gpu or cpu\n",
    "    model.to(device)\n",
    "    # set model to train mode    \n",
    "    model.train()        \n",
    "\n",
    "    # initialise optimiser\n",
    "    if solver.lower() == \"adam\": \n",
    "        optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif solver.lower == \"sgd\":\n",
    "        optimiser = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # initialise loss function: cross-entropy loss\n",
    "    criterion = nn.CrossEntropyLoss()     \n",
    "    \n",
    "    # initialise the hidden state of the RNN to zeros\n",
    "    hidden = model.init_hidden(batch_size, device)       \n",
    "    \n",
    "    measures = defaultdict(list)\n",
    "    best_model = copy.deepcopy(model)\n",
    "    best_val = np.inf\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        train_loss = train_corr = 0.\n",
    "\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            # detach hidden state from history\n",
    "            hidden = model.repackage_hidden(hidden)            \n",
    "            \n",
    "            x, y = batch.text.T, batch.target.T\n",
    "            \n",
    "            # zero accumulated gradients\n",
    "            optimiser.zero_grad()\n",
    "            \n",
    "            # forward Propogation: get prediction from model\n",
    "            preds, hidden = model(x, hidden)         \n",
    "            \n",
    "            # calculate the loss\n",
    "            loss = criterion(preds.reshape(-1, model.input_size), \n",
    "                             y.reshape(-1))              \n",
    "       \n",
    "            # backpropogation: calculating gradients\n",
    "            loss.backward()\n",
    "            # prevent the exploding gradient problem in RNNs/LSTMs.\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            # update weights\n",
    "            optimiser.step()\n",
    "            \n",
    "            # append the train loss\n",
    "            train_loss += loss.item()*x.size(0)*x.size(1)      \n",
    "            # get number of tokens correct \n",
    "            preds = preds.max(2)[1].cpu().numpy()\n",
    "            y = y.cpu().numpy()\n",
    "            train_corr += int((preds == y).sum())  \n",
    "\n",
    "        # set model to evaluate mode\n",
    "        model.eval() \n",
    "        # get new hidden states for RNN \n",
    "        val_hidden = model.init_hidden(batch_size, device)           \n",
    "        # monitor the validation loss\n",
    "        val_loss = val_corr = 0.        \n",
    "        with torch.no_grad():\n",
    "            for j, batch in enumerate(val_iter):                    \n",
    "                x, y = batch.text.T, batch.target.T\n",
    "                # get validation prediction\n",
    "                preds, val_hidden = model(x, val_hidden)          \n",
    "                # get validaiton loss\n",
    "                loss = criterion(preds.reshape(-1, model.input_size), \n",
    "                                 y.reshape(-1)) \n",
    "                # add the validation loss\n",
    "                val_loss += loss.item()*x.size(0)*x.size(1)      \n",
    "                # get number of tokens correct  \n",
    "                preds = preds.max(2)[1].cpu().numpy()\n",
    "                y = y.cpu().numpy()\n",
    "                val_corr += int((preds == y).sum()) \n",
    "\n",
    "        # put model to train mode\n",
    "        model.train()      \n",
    "        \n",
    "        # save losses from epoch\n",
    "        train_loss /= len(train_iter.dataset.examples[0].text)\n",
    "        val_loss /= len(val_iter.dataset.examples[0].text)\n",
    "        measures[\"Train loss\"].append(train_loss)\n",
    "        measures[\"Val loss\"].append(val_loss)\n",
    "        # save accuracies from epoch\n",
    "        train_corr /= len(train_iter.dataset.examples[0].text)\n",
    "        val_corr /= len(val_iter.dataset.examples[0].text)      \n",
    "        measures[\"Train acc\"].append(train_corr)\n",
    "        measures[\"Val acc\"].append(val_corr)        \n",
    "        \n",
    "        print(\"Epoch: {}/{}...\".format(epoch+1, epochs),\n",
    "              \"Train Loss: {:.4f}...\".format(train_loss),\n",
    "              \"Val Loss: {:.4f}...\".format(val_loss),\n",
    "              \"Time Taken: {:,.4f} seconds\".format(time.time()-start_time))\n",
    "        print(\"Train Acc: {:.4f}...\".format(train_corr),\n",
    "              \"Val Acc: {:.4f}\".format(val_corr)) \n",
    "\n",
    "        # save best model\n",
    "        if measures[\"Val loss\"][-1] < best_val:\n",
    "            best_val = measures[\"Val loss\"][-1]\n",
    "            best_model = copy.deepcopy(model)\n",
    "            \n",
    "        # early stopping condition for convergence on validation.\n",
    "        win_size = 10\n",
    "        threshold = 0.00005        \n",
    "        try:\n",
    "            curr_avg = np.mean(measures[\"Val loss\"][-1-win_size:-1])\n",
    "            prev_avg = np.mean(measures[\"Val loss\"][-win_size*2:-win_size])\n",
    "            if np.absolute(curr_avg - prev_avg) < threshold:\n",
    "                break\n",
    "        except:\n",
    "            pass \n",
    "    \n",
    "    return best_model, measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Train Loss: 0.0030... Val Loss: 0.0282... Time Taken: 1.0481 seconds\n",
      "Train Acc: 0.0000... Val Acc: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/anaconda3/envs/nlp/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "best_model, measures = train(model=rnn, \n",
    "                             train_iter=train_iter, \n",
    "                             val_iter=val_iter, \n",
    "                             epochs=epochs, \n",
    "                             batch_size=batch_size, \n",
    "                             seq_len=seq_len, \n",
    "                             learning_rate=learning_rate, \n",
    "                             clip=clip,\n",
    "                             solver=solver,\n",
    "                             device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot train and validation loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(measures[\"Train loss\"], label=\"Train Loss\")\n",
    "plt.plot(measures[\"Val loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Loss Plot\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot train and validation acc\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(measures[\"Train acc\"], label=\"Train Acc\")\n",
    "plt.plot(measures[\"Val acc\"], label=\"Validation Acc\")\n",
    "plt.title(\"Accuracy Plot\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, \n",
    "             test_iter, \n",
    "             batch_size, \n",
    "             seq_len,\n",
    "             device):\n",
    "    \"\"\"\n",
    "    Evaluate model on data and calculate accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : `torch.nn.Module` \n",
    "        The model.\n",
    "    test_iter : `torchtext.data.iterator.BPTTIterator`\n",
    "        The test data iterator.\n",
    "    batch_size : `int`\n",
    "        The number of sequences per batch.\n",
    "    seq_len : `int`\n",
    "        The number of encoded chars in a sequence.\n",
    "    device : `torch.device`\n",
    "        Whether working on GPU or CPU.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    acc : `float`\n",
    "        The accuracy of the model on the data predicted over\n",
    "    \"\"\"    \n",
    "    # send model to device\n",
    "    model.to(device)\n",
    "    # set to evaluate mode\n",
    "    model.eval()    \n",
    "    \n",
    "    # get new hidden state for RNN\n",
    "    hidden = model.init_hidden(batch_size)          \n",
    "    # accuracy stats after every epoch\n",
    "    eval_corr = 0    \n",
    "    for i, batch in enumerate(test_iter):\n",
    "        x, y = batch.text.T, batch.target.T\n",
    "        # get validation prediction\n",
    "        preds, hidden = model(x, hidden)             \n",
    "        # get number of tokens correct  \n",
    "        preds = preds.max(2)[1].cpu().numpy()\n",
    "        y = y.cpu().numpy()\n",
    "        eval_corr += int((preds == y).sum())           \n",
    "    acc = eval_corr / len(test_iter.dataset.examples[0].text)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = evaluate(model=best_model, \n",
    "                     test_iter=train_iter, \n",
    "                     batch_size=batch_size, \n",
    "                     seq_len=seq_len,\n",
    "                     device=device)\n",
    "val_acc = evaluate(model=best_model, \n",
    "                   test_iter=val_iter, \n",
    "                   batch_size=batch_size, \n",
    "                   seq_len=seq_len,\n",
    "                   device=device)\n",
    "test_acc = evaluate(model=best_model, \n",
    "                    test_iter=test_iter, \n",
    "                    batch_size=batch_size, \n",
    "                    seq_len=seq_len,\n",
    "                    device=device)\n",
    "print(\"Final train accuracy: \", train_acc)\n",
    "print(\"Final val accuracy:   \", val_acc)\n",
    "print(\"Final test accuracy:  \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Softmax activation function for a vector $\\mathbf{z}\\in\\mathbb{R}^{N}$ is given by\n",
    "$$\\sigma(\\mathbf{z})_i=\\frac{e^{z_i}}{\\sum^{N}_{j=1}e^{z}_j}\\in[0,1]$$\n",
    "Thus this is useful for convert the output layer values pre-application of the activation function to probabilities.\n",
    "\n",
    "* Sigmoid activation function for a scalar $z\\in\\mathbb{R}$ is given by\n",
    "$$\\sigma(z)=\\frac{1}{1+e^{-z}}\\in[0,1]$$\n",
    "This can be used to convert the output value of a neural network (single output node) pre-application of the activation function to a probability. Thus used for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, \n",
    "           size, \n",
    "           device,\n",
    "           prime=\"The\", \n",
    "           top_k=None):\n",
    "    \"\"\"\n",
    "    Given a initial sequence `prime` predicted the following \n",
    "    words.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : `torch.nn.Module`\n",
    "        The recurrent network model. \n",
    "    size : `int`\n",
    "        The number of tokens to predict\n",
    "    device : `torch.device`\n",
    "        Whether working on GPU or CPU.          \n",
    "    prime : `str`\n",
    "        The starting sequence to predict from.\n",
    "    top_k : `int`\n",
    "        The number of top tokens to draw the final token from.       \n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    text : `str`\n",
    "        The prime with predicted next tokens.\n",
    "    \"\"\"\n",
    "    # send model to device\n",
    "    model.to(device)\n",
    "    # set model to evaluate mode\n",
    "    model.eval()\n",
    "            \n",
    "    # tokenize the prime\n",
    "    tokens = TEXT.preprocess(prime)\n",
    "    # get new hidden state for testing\n",
    "    hidden = model.init_hidden(batch_size=1, device=device)\n",
    "    # iterate through tokens in prime to build up hidden state\n",
    "    for token in tokens:\n",
    "        token, hidden = predict(model, token, hidden, top_k=top_k)\n",
    "    # append the final token to the prime\n",
    "    tokens.append(token)\n",
    "    \n",
    "    if size>1:\n",
    "        # now pass in the previous character and get a new one\n",
    "        for _ in range(size-1):\n",
    "            token, hidden = predict(model, tokens[-1], hidden, top_k=top_k)\n",
    "            tokens.append(token)\n",
    "            \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def predict(model, \n",
    "            token, \n",
    "            hidden, \n",
    "            device,\n",
    "            top_k=None):\n",
    "    \"\"\"\n",
    "    Given a character, predict the next character\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : `torch.nn.Module`\n",
    "        The recurrent network model.\n",
    "    token : `str`\n",
    "        The previous token for which we must predict the next.\n",
    "    hidden : `torch.Tensor` or `tuple`\n",
    "        The hidden state of the RNN.\n",
    "    device : `torch.device`\n",
    "        Whether working on GPU or CPU.             \n",
    "    top_k : `int`\n",
    "        The number of top tokens to draw the final token from.   \n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    top_token : `str`\n",
    "        The top token predicted by the model.\n",
    "    hidden : `torch.Tensor` or `tuple`\n",
    "        The hidden state of the RNN.    \n",
    "    \"\"\" \n",
    "    # encode the token to an integer\n",
    "    enc_x = torch.LongTensor([TEXT.vocab.stoi[token]])\n",
    "    # add extra dimension to indicate batch_size of 1, [batch_size=1, seq_len=1]\n",
    "    enc_x = enc_x.unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # forward pass through model\n",
    "        pred, hidden = model(enc_x, hidden)\n",
    "\n",
    "    # get the character probabilities\n",
    "    p = F.softmax(pred, dim=2).data.cpu()\n",
    "    # get most likely characters\n",
    "    if top_k is None:\n",
    "        # all chars are the top chars\n",
    "        top_token = np.arange(model.input_size)\n",
    "    else:\n",
    "        # return the prob and the top_k top_tokens \n",
    "        p, top_tokens = p.topk(top_k)\n",
    "        top_tokens = top_tokens.numpy().squeeze()\n",
    "    \n",
    "    # select the likely next character with some element of randomness\n",
    "    p = p.numpy().squeeze()\n",
    "    top_token = np.random.choice(top_tokens, p=p/p.sum())\n",
    "    # return the encoded value of the predicted char and the hidden state\n",
    "    return TEXT.vocab.itos[top_token], hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello how prejudice'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(model=rnn, \n",
    "       size=1,\n",
    "       device=device,\n",
    "       prime=\"hello how\", \n",
    "       top_k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
